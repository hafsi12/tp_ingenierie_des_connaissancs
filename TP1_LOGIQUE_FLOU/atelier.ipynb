{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b05228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération du dataset (2000 échantillons)…\n",
      "Dataset sauvegardé -> output\\fuzzy_dataset_2000.csv\n",
      "\n",
      "Entraînement des modèles ML…\n",
      "\n",
      "Métriques :\n",
      "- linear_regression: RMSE=2.0269, R2=0.5042\n",
      "- random_forest: RMSE=0.3909, R2=0.9816\n",
      "\n",
      "Importances (Random Forest) :\n",
      "  temperature: 0.4227\n",
      "  vibration: 0.4362\n",
      "  age: 0.1412\n",
      "\n",
      "Modèles sauvegardés -> output\\linear_regression.joblib, output\\random_forest.joblib\n",
      "Performances sauvegardées -> output\\model_performance.csv\n",
      "Exemples de comparaison sauvegardés -> output\\examples_comparison.csv\n",
      "Graphique True vs Pred sauvegardé -> output\\true_vs_pred_rf.png\n",
      "\n",
      "Terminé.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "fuzzy_risk_complete_code.py\n",
    "\n",
    "Script complet pour :\n",
    "- définir un contrôleur flou (Mamdani) selon la spécification\n",
    "- générer 2000 échantillons, calculer le risque défuzzifié\n",
    "- entraîner deux modèles ML (LinearRegression, RandomForest)\n",
    "- comparer les performances, sauvegarder dataset et modèles\n",
    "\n",
    "Dépendances : numpy, pandas, scikit-learn, matplotlib, joblib\n",
    "Exécution : python fuzzy_risk_complete_code.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# ------------------------\n",
    "# Fonctions utilitaires\n",
    "# ------------------------\n",
    "\n",
    "def tri(x, a, b, c):\n",
    "    \"\"\"Fonction d'appartenance triangulaire vectorisée.\"\"\"\n",
    "    x = np.array(x, dtype=float)\n",
    "    y = np.zeros_like(x)\n",
    "    # montée\n",
    "    left = (x >= a) & (x <= b)\n",
    "    if b != a:\n",
    "        y[left] = (x[left] - a) / (b - a)\n",
    "    else:\n",
    "        y[left] = 1.0\n",
    "    # descente\n",
    "    right = (x >= b) & (x <= c)\n",
    "    if c != b:\n",
    "        y[right] = (c - x[right]) / (c - b)\n",
    "    else:\n",
    "        y[right] = 1.0\n",
    "    y = np.clip(y, 0, 1)\n",
    "    return y\n",
    "\n",
    "# ------------------------\n",
    "# Définition des MFs\n",
    "# ------------------------\n",
    "\n",
    "def fuzzify_temperature(T):\n",
    "    return {\n",
    "        'basse': tri(T, 0, 0, 40),\n",
    "        'normale': tri(T, 30, 50, 70),\n",
    "        'elevee': tri(T, 60, 100, 100)\n",
    "    }\n",
    "\n",
    "def fuzzify_vibration(V):\n",
    "    return {\n",
    "        'faible': tri(V, 0, 0, 4),\n",
    "        'moyenne': tri(V, 2, 5, 8),\n",
    "        'forte': tri(V, 6, 10, 10)\n",
    "    }\n",
    "\n",
    "def fuzzify_age(A):\n",
    "    return {\n",
    "        'neuf': tri(A, 0, 0, 7),\n",
    "        'moyen': tri(A, 5, 10, 15),\n",
    "        'ancien': tri(A, 12, 20, 20)\n",
    "    }\n",
    "\n",
    "# Domaine de sortie (risque)\n",
    "risk_x = np.linspace(0, 10, 401)\n",
    "risk_fuzzy = {\n",
    "    'faible': tri(risk_x, 0, 0, 4),\n",
    "    'moyen': tri(risk_x, 2, 5, 8),\n",
    "    'eleve': tri(risk_x, 6, 10, 10)\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "# Règles et inférence\n",
    "# ------------------------\n",
    "\n",
    "def infer_risk(T, V, A):\n",
    "    \"\"\"Infère le risque (valeur défuzzifiée) pour une triple (T,V,A).\n",
    "    Méthode: Mamdani (min pour AND, max pour OR), agrégation par max, centre de gravité.\n",
    "    \"\"\"\n",
    "    t_m = fuzzify_temperature(T)\n",
    "    v_m = fuzzify_vibration(V)\n",
    "    a_m = fuzzify_age(A)\n",
    "\n",
    "    # degrés d'activation\n",
    "    r1 = max(t_m['elevee'], v_m['forte'])                        # OR\n",
    "    r2 = min(a_m['ancien'], v_m['moyenne'])                      # AND\n",
    "    r3 = min(t_m['basse'], v_m['faible'], a_m['neuf'])           # AND\n",
    "    r4 = min(t_m['normale'], a_m['moyen'])                       # AND\n",
    "\n",
    "    # agrégation (clipping)\n",
    "    agg = np.zeros_like(risk_x)\n",
    "    if r1 > 0:\n",
    "        agg = np.maximum(agg, np.minimum(r1, risk_fuzzy['eleve']))\n",
    "    if r2 > 0:\n",
    "        agg = np.maximum(agg, np.minimum(r2, risk_fuzzy['moyen']))\n",
    "    if r3 > 0:\n",
    "        agg = np.maximum(agg, np.minimum(r3, risk_fuzzy['faible']))\n",
    "    if r4 > 0:\n",
    "        agg = np.maximum(agg, np.minimum(r4, risk_fuzzy['moyen']))\n",
    "\n",
    "    # défuzzification (centroid)\n",
    "    if agg.sum() == 0:\n",
    "        return 0.0\n",
    "    centroid = (risk_x * agg).sum() / agg.sum()\n",
    "    return float(centroid)\n",
    "\n",
    "# ------------------------\n",
    "# Génération du dataset\n",
    "# ------------------------\n",
    "\n",
    "def generate_dataset(N=2000, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    temps = np.random.uniform(0, 100, N)\n",
    "    vibs = np.random.uniform(0, 10, N)\n",
    "    ages = np.random.uniform(0, 20, N)\n",
    "    risks = np.array([infer_risk(t, v, a) for t, v, a in zip(temps, vibs, ages)])\n",
    "    df = pd.DataFrame({'temperature': temps, 'vibration': vibs, 'age': ages, 'risk_fuzzy': risks})\n",
    "    return df\n",
    "\n",
    "# ------------------------\n",
    "# Entraînement des modèles\n",
    "# ------------------------\n",
    "\n",
    "def train_models(df, test_size=0.2, random_state=1):\n",
    "    X = df[['temperature', 'vibration', 'age']].values\n",
    "    y = df['risk_fuzzy'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    lr = LinearRegression().fit(X_train, y_train)\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=random_state).fit(X_train, y_train)\n",
    "\n",
    "    # prédictions\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        return {\n",
    "            'MSE': mean_squared_error(y_true, y_pred),\n",
    "            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'R2': r2_score(y_true, y_pred)\n",
    "        }\n",
    "\n",
    "    metrics_lr = metrics(y_test, y_pred_lr)\n",
    "    metrics_rf = metrics(y_test, y_pred_rf)\n",
    "\n",
    "    # importances\n",
    "    feat_imp = {\n",
    "        'features': ['temperature', 'vibration', 'age'],\n",
    "        'importance': rf.feature_importances_.tolist()\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'models': {\n",
    "            'linear_regression': lr,\n",
    "            'random_forest': rf\n",
    "        },\n",
    "        'metrics': {\n",
    "            'linear_regression': metrics_lr,\n",
    "            'random_forest': metrics_rf\n",
    "        },\n",
    "        'feature_importances': feat_imp,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'y_pred_lr': y_pred_lr,\n",
    "        'y_pred_rf': y_pred_rf\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# ------------------------\n",
    "# Visualisations & sauvegarde\n",
    "# ------------------------\n",
    "\n",
    "def plot_true_vs_pred(y_true, y_pred, title=\"True vs Predicted\", filename=None):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.4)\n",
    "    plt.plot([0,10],[0,10], linestyle='--')\n",
    "    plt.xlabel(\"Risk (fuzzy, true)\")\n",
    "    plt.ylabel(\"Risk (predicted)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    if filename:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ------------------------\n",
    "# Main\n",
    "# ------------------------\n",
    "\n",
    "def main():\n",
    "    out_dir = 'output'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    print(\"Génération du dataset (2000 échantillons)…\")\n",
    "    df = generate_dataset(N=2000, seed=42)\n",
    "    csv_path = os.path.join(out_dir, 'fuzzy_dataset_2000.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Dataset sauvegardé -> {csv_path}\")\n",
    "\n",
    "    print(\"\\nEntraînement des modèles ML…\")\n",
    "    results = train_models(df)\n",
    "\n",
    "    # afficher les métriques\n",
    "    print(\"\\nMétriques :\")\n",
    "    for name, m in results['metrics'].items():\n",
    "        print(f\"- {name}: RMSE={m['RMSE']:.4f}, R2={m['R2']:.4f}\")\n",
    "\n",
    "    # importances\n",
    "    print(\"\\nImportances (Random Forest) :\")\n",
    "    for f, imp in zip(results['feature_importances']['features'], results['feature_importances']['importance']):\n",
    "        print(f\"  {f}: {imp:.4f}\")\n",
    "\n",
    "    # sauvegarder modèles\n",
    "    lr_path = os.path.join(out_dir, 'linear_regression.joblib')\n",
    "    rf_path = os.path.join(out_dir, 'random_forest.joblib')\n",
    "    joblib.dump(results['models']['linear_regression'], lr_path)\n",
    "    joblib.dump(results['models']['random_forest'], rf_path)\n",
    "    print(f\"\\nModèles sauvegardés -> {lr_path}, {rf_path}\")\n",
    "\n",
    "    # sauvegarder performances\n",
    "    perf_df = pd.DataFrame([\n",
    "        {'model': 'LinearRegression', **results['metrics']['linear_regression']},\n",
    "        {'model': 'RandomForest', **results['metrics']['random_forest']}\n",
    "    ])\n",
    "    perf_path = os.path.join(out_dir, 'model_performance.csv')\n",
    "    perf_df.to_csv(perf_path, index=False)\n",
    "    print(f\"Performances sauvegardées -> {perf_path}\")\n",
    "\n",
    "    # exemples de comparaison\n",
    "    examples = np.array([\n",
    "        [85, 8.5, 15],\n",
    "        [25, 1.0, 1],\n",
    "        [45, 5.0, 10],\n",
    "        [70, 3.0, 18],\n",
    "        [55, 6.5, 3],\n",
    "        [30, 2.0, 12]\n",
    "    ])\n",
    "    examples_df = pd.DataFrame(examples, columns=['temperature','vibration','age'])\n",
    "    examples_df['risk_fuzzy'] = [infer_risk(*row) for row in examples]\n",
    "    examples_df['risk_lr'] = results['models']['linear_regression'].predict(examples)\n",
    "    examples_df['risk_rf'] = results['models']['random_forest'].predict(examples)\n",
    "    examples_path = os.path.join(out_dir, 'examples_comparison.csv')\n",
    "    examples_df.to_csv(examples_path, index=False)\n",
    "    print(f\"Exemples de comparaison sauvegardés -> {examples_path}\")\n",
    "\n",
    "    # graphiques\n",
    "    plot_true_vs_pred(results['y_test'], results['y_pred_rf'], title='True vs Predicted (Random Forest)', filename=os.path.join(out_dir, 'true_vs_pred_rf.png'))\n",
    "    print(f\"Graphique True vs Pred sauvegardé -> {os.path.join(out_dir, 'true_vs_pred_rf.png')}\")\n",
    "\n",
    "    print('\\nTerminé.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
